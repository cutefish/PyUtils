I want to automate the whole experiment process to some extend.

Each experiment project has a root directory <project>, inside which there are
three subdirs <project>/config, <project>/data, <project>/result.

In my view, experiments are a set of mappings between (ivars, dvars),
therefore, each experiment point is a key value pair of (ivars, dvars). To
support multiple iteration, I extend the tuple to (ivars, dvars, iterno).

1. Configure Experiments
1.1 Description
The <project>/config subdir is a collection of configure files each of which
specify how to run an experiment point (ivars, dvars). Each configure file is a
list of configures and command args for each exp point. Each experiment point
is given an integer id number for easy identification purpose. The configure
file is in the following format to be recognized by the follow-up steps:

...
##### EXPERIMENT POINT #####
experiment.point.id = $id
experiment.run.command = "$command"
... ivars ...
##### END #####
...

1.2 Generating config files
To automate the generation of config files, first, there is a
<project>/config/__count__ file which keeps the count of all the experiment
points and is used to give identification number.

A config file is generated according to the following parameters:
    * command
    * consts
    * vars
Run command is the command of how to run an experiment point, which may take
values from consts or variables. Consts are key/value pairs where value is a
single number and keeps the same for all the exp points during this configure
generation. Variables are key/values pairs where values are a list of values.
Each experiment point takes one of the value. Consts are in the form "key =
value". Values support value expansion form $var. Variables are in the form
"key = [value1, value2...]" or "key1, key2 = [(value11, value12), (value21,
value22), ...]

For example:
    command:
        python -m addTwoValues $x $y
    consts:
        x = 10
    vars:
        y = [1, 2, 3, 4]
This will generate a configure file with 4 experiment points:
    ##### EXPERIMENT POINT #####
    experiment.point.id = 1
    experiment.run.command = "python -m addTwoValues 10 1"
    x = 10
    y = 1
    ##### END #####
    ##### EXPERIMENT POINT #####
    experiment.point.id = 2
    experiment.run.command = "python -m addTwoValues 10 2"
    x = 10
    y = 2
    ##### END #####
    ...

The configuration file can be generated from command line or a generation file.
To use configuration tool, type:
    pyutils exp.auto config command <command> <out> [--consts consts, --vars vars]
        --consts      --  "k1=v1;k2=v2;k3=v3"
        --vars        --  "k1=[v1,v2,v3];k2=[w1,w2,w3]" or "k1,k2=[(v1,w1),(v2,w2),(v3,w3)]"
or
    pyutils exp.auto config file <config file> <out>
For example:
    pyutils exp.auto config command "python -m addTwoValues $x $y" out --consts x=10 --vars y=1,2,3,4

The generation file is in the form
    #command
    <command>
    #consts
    ...
    #vars
    ...
For example:
    #command:
    python -m addTwoValues $x $y

    #consts:
    x = 10

    #vars:
    y = [1, 2, 3, 4]

2. Run Experiments
The experiment running process runs on a set of configuration files and produce
result in <project>/data directory. Run is invoked through command line using
    pyutils exp.run <project dir> <run range> [num processes]
When run the experiments, each point will put a new directory in
<project>/data/<num> such that all the data or logs of that experiment point is
kept in the directory. Inside each of those directories, we keep an index file
<project>/data/<num>/index which record the ivars of this exp point.

3. Process Experiment Results
3.1 Description
The automation of process results includes pre-processing and other analysis of
results such as plot or make a table. Pre-processing includes parsing the logs
and data from <project>/data directory and builds a map of {ivars:[(num, dvars)]} at
<project>/result/index.  This map data structure is usually built in a
accumulated manner. After the pre-processing step, other analysis tools can be
used to utilize this map to do further analysis on the data.

3.2 Pre-processing
The pre-processing is invoked by the command line:
    pyutils exp.preproc <project dir> <proc range>
Pre-processing involves customized parsing the files inside each
<project>/data/<num>. We first reads the <project>/data/<num>/index to get the
ivars. Then the <project>/result/index is checked to see if <num> is already
parsed.

To customize the pre-processing steps is to define file filters and dvars
extractors. These customizations are defined in a preproc config file in the format
#key [key1, key2, ...]
filter.include=<file name regex>
extractor=SingleDVarExtractor
